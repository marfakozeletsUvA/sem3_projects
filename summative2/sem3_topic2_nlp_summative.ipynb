{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0-markdown",
   "metadata": {},
   "source": [
    "# Semester 3 Coding Portfolio Topic 2 Summative:\n",
    "# Natural Language Processing\n",
    "\n",
    "In this notebook, you are asked to do original work with little guidance, based on the skills you learned in the formative part (as well as lectures and workshops).\n",
    "This section is graded not just on passing automated tests, but also on quality, originality, and effort (see assessment criteria in the assignment description)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Please enter your student number here\n",
    "STUDENT_NUMBER = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2-markdown",
   "metadata": {},
   "source": [
    "# SUMMATIVE ASSESSMENT\n",
    "\n",
    "For this summative assignment, we ask you to find a dataset from an internet source of choice. You will then create an NLP pipeline including preprocessing, NLP analysis, and classification.\n",
    "Your anlysis for this notebook should have two parts: An initial NLP analysis (as done in formative notebook 1), and a classification of these results (as done in formative notebook 2). Chose one method for each of these two steps.\n",
    "\n",
    "You should chose ONE of the following:\n",
    " - Sentiment Analysis\n",
    " - LDA\n",
    " - BertTopic\n",
    "\n",
    "You should ALSO chose ONE of the following:\n",
    " - Decision Tree / Random Forest\n",
    " - LLM-based text classification\n",
    "\n",
    "\n",
    "The general assessment criteria for all summative assignments are mentioned in the assignment description on Canvas. Each notebook also has a few specific criteria we look for; make sure you fulfil them in your approach to this assignment.\n",
    "In general, make sure this notebook represents a complete project: Write an explanation of what you are hoping to achieve with your analysis, document your code well, and present results in a comprehensive way.\n",
    "The assessment criteria for this notebook vary slightly depending on which methods you chose to implement:\n",
    "\n",
    "## Sentiment Analysis\n",
    " - Selected an appropriate dataset and prepared it for analysis, including cleaning and formatting the data.\n",
    " - Effectively pre-processed the text data, including steps such as tokenization, stopword removal, lemmatization, and handling special characters.\n",
    " - Selected an appropriate sentiment analysis model or algorithm for their dataset and correctly implemented the sentiment analysis model, ensuring it is properly trained and tested.\n",
    " - Provided a clear and insightful interpretation of the sentiment analysis results, explaining the significance and implications of their findings.\n",
    "\n",
    "## LDA \n",
    " - Selected an appropriate dataset and prepared it for analysis, including cleaning and formatting the data.\n",
    " - Correctly created a document-term matrix or equivalent representation suitable for LDA.\n",
    " - Selected appropriate parameters for the LDA model, such as the number of topics and hyperparameters.\n",
    " - Correctly implemented the LDA model, ensuring it is properly trained on the dataset.\n",
    " - Provided a clear and insightful interpretation of the topics, explaining the significance and relevance of the discovered topics.\n",
    "\n",
    "## BertTopic\n",
    " - Selected an appropriate dataset and prepared it for analysis, including cleaning and formatting the data.\n",
    " - Correctly generated text embeddings using a suitable model for input into BERTopic.\n",
    " - Correctly implemented the BERTopic model, ensuring it is properly trained on the dataset.\n",
    " - Accurately extracted and represented topics from the BERTopic model.\n",
    " - Provided a clear and insightful interpretation of the topics, explaining the significance and relevance of the discovered topics.\n",
    "\n",
    "## Decision Tree / Random Forest\n",
    " - Formulated a relevant and appropriate classification objective for the NLP task.\n",
    " - Pre-processed the text data appropriately, including vecterization and other necessary steps.\n",
    " - Properly trained and tested the decision tree or random forest model.\n",
    " - Accurately print or visualize the results, or provide insightful interpretation of the findings.\n",
    "\n",
    "## LLM-based text classification\n",
    " - Formulated a relevant and appropriate classification objective for the NLP task.\n",
    " - Correctly prepared the data for the LLM, ensuring it is suitable for model input.\n",
    " - Properly ran the LLM and tested the LLM output.\n",
    " - Accurately print or visualize the results, or provide insightful interpretation of the findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3-markdown",
   "metadata": {},
   "source": [
    "Pick a dataset of your choice. Please ensure your dataset is a csv file under 100MB named sem3_topic2_nlp_summative_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do NOT modify the contents of this cell. Start your customization in the next one!\n",
    "import pandas as pd\n",
    "\n",
    "custom_data_path = \"sem3_topic2_nlp_summative_data.csv\"\n",
    "custom_df = pd.read_csv(custom_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5646127",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td style=\"vertical-align: top; padding-right: 20px;\">\n",
    "\n",
    "<h2>BACKSTORY</h2>\n",
    "\n",
    "<p>\n",
    "Religion has always been an interesting topic for me. My parents never baptised me, choosing instead to let me decide my own beliefs when I was old enough. Still, my mother is strongly Orthodox, so growing up we celebrated Christmas on the night of the 6th to the 7th of January.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Now, living in Amsterdam, I have a Christian boyfriend. This year I will be joining his family for a Catholic Christmas celebration. They are very religious people, and as a respectful girlfriend I decided to use this summative project as an opportunity to impress my “mother-in-law” with my growing Bible knowledge.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "So in this notebook I will be <b>(1) exploring different topics that emerge throughout Bible verses</b>, and <b>(2) training a model to classify each verse into its discovered topic.\n",
    "</b>\n",
    "\n",
    "<p>\n",
    "the image was generated with ChatGPT\n",
    "</p>\n",
    "\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "    <img src=\"cross-bible.png\" width=\"850\">\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30329f80",
   "metadata": {},
   "source": [
    "**RQ: Can topic modelling reveal meaningful themes in Bible verses, and can we automatically classify each verse into its discovered topic using a machine-learning model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb54a44",
   "metadata": {},
   "source": [
    "**DEVELOPING A PIPELINE**\n",
    "\n",
    "\n",
    "below I revisit Fromative ipynb 1 to figure out NLP pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a0a111",
   "metadata": {},
   "source": [
    "## Preprocessing the text for NLP\n",
    "Preprocessing can involve some combination of the following steps. Which steps to use depends on what you want to do.\n",
    "\n",
    "1. *Remove unwanted or empty messages.* We start by cleaning the data, removing messages that are unlikely to contain any useful text.\n",
    "\n",
    "2. *Text Cleaning.*\n",
    "The first step is to clean the text. We remove any irrelevant items like HTML tags, URLs, and codes when dealing with web data. We also get rid of special characters, numbers, or punctuation that might not be necessary for analysis.\n",
    "\n",
    "3. *Case Normalization.*\n",
    "Next, we normalize the case by converting all the text to lower case. This ensures that words like 'House', 'house', and 'HOUSE' are all treated as the same word, preventing the model from treating them as different entities.\n",
    "\n",
    "4. *Tokenization.*\n",
    "Then we move to tokenization. This is where we break down the text into smaller pieces, or tokens. Tokens can be words, phrases, or even sentences. In English, this might seem as simple as splitting by spaces, but it can get complicated with languages that don’t use spaces or have complex morphology.\n",
    "\n",
    "5. *Stop Words Removal.*\n",
    "After tokenization, we often remove stop words. These are common words like 'is', 'and', 'the', which appear frequently in the text but usually don’t carry significant meaning for the analysis.\n",
    "\n",
    "6. *Lemmatization.*\n",
    "Now, we refine our tokens using ste lemmatization. This strips the words down to their root form. For example, 'running', 'runs', and 'ran' might all be reduced to 'run'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5de1fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#core\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#text preprocessing\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#vectorization\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "#LDA topic modelling\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "#BERTopic\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#evaluation\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "#visuals\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#NLTK \n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8684eba2",
   "metadata": {},
   "source": [
    "(0) **DATA PREPROCESSING**\n",
    "\n",
    "\n",
    "My original dataset is json so I need to convert into csv to satisfy assingment criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c95521ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load JSON\n",
    "with open(\"ASV.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "rows = []\n",
    "\n",
    "for book in data[\"books\"]:\n",
    "    book_name = book[\"name\"]\n",
    "    for chapter in book[\"chapters\"]:\n",
    "        chapter_num = chapter[\"chapter\"]\n",
    "        for verse in chapter[\"verses\"]:\n",
    "            verse_num = verse[\"verse\"]\n",
    "            text = verse[\"text\"]\n",
    "            rows.append({\n",
    "                \"book\": book_name,\n",
    "                \"chapter\": chapter_num,\n",
    "                \"verse\": verse_num,\n",
    "                \"text\": text\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# IMPORTANT: use quoting to prevent broken columns\n",
    "df.to_csv(\"sem3_topic2_nlp_summative_data.csv\", index=False, quoting=1)  # quoting=1 == csv.QUOTE_ALL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8c9f99",
   "metadata": {},
   "source": [
    "Upon manual inspection my generated csv looked broken, so I check df head and info to see that the verses actually loaded correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa2f3852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31102 entries, 0 to 31101\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   book     31102 non-null  object\n",
      " 1   chapter  31102 non-null  int64 \n",
      " 2   verse    31102 non-null  int64 \n",
      " 3   text     31102 non-null  object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 972.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"sem3_topic2_nlp_summative_data.csv\")\n",
    "df.head()\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fd6736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      book  chapter  verse                                               text\n",
      "0  Genesis        1      1  In the beginning God created the heavens and t...\n",
      "1  Genesis        1      2  And the earth was waste and void; and darkness...\n",
      "2  Genesis        1      3  And God said, Let there be light: and there wa...\n",
      "3  Genesis        1      4  And God saw the light, that it was good: and G...\n",
      "4  Genesis        1      5  And God called the light Day, and the darkness...\n",
      "In the beginning God created the heavens and the earth. \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"sem3_topic2_nlp_summative_data.csv\")\n",
    "print(df.head())\n",
    "print(df.iloc[0][\"text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877963e5",
   "metadata": {},
   "source": [
    "(1) **PREPROCESSING FOR BERTOPIC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "878ec548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>chapter</th>\n",
       "      <th>verse</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>In the beginning God created the heavens and t...</td>\n",
       "      <td>in the beginning god created the heavens and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>And the earth was waste and void; and darkness...</td>\n",
       "      <td>and the earth was waste and void and darkness ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>And God said, Let there be light: and there wa...</td>\n",
       "      <td>and god said let there be light and there was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>And God saw the light, that it was good: and G...</td>\n",
       "      <td>and god saw the light that it was good and god...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>And God called the light Day, and the darkness...</td>\n",
       "      <td>and god called the light day and the darkness ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      book  chapter  verse                                               text  \\\n",
       "0  Genesis        1      1  In the beginning God created the heavens and t...   \n",
       "1  Genesis        1      2  And the earth was waste and void; and darkness...   \n",
       "2  Genesis        1      3  And God said, Let there be light: and there wa...   \n",
       "3  Genesis        1      4  And God saw the light, that it was good: and G...   \n",
       "4  Genesis        1      5  And God called the light Day, and the darkness...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  in the beginning god created the heavens and t...  \n",
       "1  and the earth was waste and void and darkness ...  \n",
       "2  and god said let there be light and there was ...  \n",
       "3  and god saw the light that it was good and god...  \n",
       "4  and god called the light day and the darkness ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"sem3_topic2_nlp_summative_data.csv\")\n",
    "\n",
    "#drop rows missing/empty text\n",
    "df['text'] = df['text'].astype(str)  # ! string type !\n",
    "df = df[df['text'].str.strip() != \"\"]  #remove empty str\n",
    "df = df.dropna(subset=['text'])        #remove NaNs\n",
    "\n",
    "#cleaning\n",
    "def clean_text(text):\n",
    "    text = text.lower()                         #lowercase\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)         #- URLs ?\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)     #- punctuation & numbers\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()    #collapse multiple spaces\n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e1f4e",
   "metadata": {},
   "source": [
    "(1.2) **PREPARE DOCS FOR BERTOPIC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef58368b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 31086\n",
      "Example document: In the beginning God created the heavens and the earth. \n"
     ]
    }
   ],
   "source": [
    "# Copy the text column as a list of documents\n",
    "documents = df['text'].astype(str).tolist()\n",
    "\n",
    "print(\"Number of documents:\", len(documents))\n",
    "print(\"Example document:\", documents[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9303075e",
   "metadata": {},
   "source": [
    "(2) **BERTOPIC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4806b5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 18:52:44,461 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165429de181943238cdcbc0f0545c704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/972 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 18:53:20,341 - BERTopic - Embedding - Completed ✓\n",
      "2025-12-01 18:53:20,341 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-12-01 18:53:33,315 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-12-01 18:53:33,316 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-12-01 18:53:36,716 - BERTopic - Cluster - Completed ✓\n",
      "2025-12-01 18:53:36,717 - BERTopic - Representation - Extracting topics using c-TF-IDF for topic reduction.\n",
      "2025-12-01 18:53:37,112 - BERTopic - Representation - Completed ✓\n",
      "2025-12-01 18:53:37,113 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2025-12-01 18:53:37,177 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-12-01 18:53:37,506 - BERTopic - Representation - Completed ✓\n",
      "2025-12-01 18:53:37,509 - BERTopic - Topic reduction - Reduced number of topics from 357 to 24\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic import BERTopic\n",
    "\n",
    "docs = df[\"clean_text\"].tolist()\n",
    "\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    nr_topics=24,        # fix the number of topics\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "042ba7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info = topic_model.get_topic_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66fb69f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>15735</td>\n",
       "      <td>-1_unto_shall_thou_thy</td>\n",
       "      <td>[unto, shall, thou, thy, god, jehovah, thee, y...</td>\n",
       "      <td>[and they that are far off shall come and buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>8241</td>\n",
       "      <td>0_jehovah_unto_said_shall</td>\n",
       "      <td>[jehovah, unto, said, shall, king, came, israe...</td>\n",
       "      <td>[and jeremiah said the word of jehovah came un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3545</td>\n",
       "      <td>1_shall_thy_thou_ye</td>\n",
       "      <td>[shall, thy, thou, ye, god, thee, unto, hath, ...</td>\n",
       "      <td>[let thy hand be upon the man of thy right han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>923</td>\n",
       "      <td>2_son_sons_years_reigned</td>\n",
       "      <td>[son, sons, years, reigned, children, thousand...</td>\n",
       "      <td>[zedekiah was twenty and one years old when he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>661</td>\n",
       "      <td>3_wife_woman_said_husband</td>\n",
       "      <td>[wife, woman, said, husband, unto, nakedness, ...</td>\n",
       "      <td>[and he came near unto her and the woman said ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>294</td>\n",
       "      <td>4_gold_silver_thereof_rings</td>\n",
       "      <td>[gold, silver, thereof, rings, fine, work, pur...</td>\n",
       "      <td>[and they shall make the ephod of gold of blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>282</td>\n",
       "      <td>5_border_suburbs_journeyed_encamped</td>\n",
       "      <td>[border, suburbs, journeyed, encamped, lebanon...</td>\n",
       "      <td>[and the border from the sea shall be hazareno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>280</td>\n",
       "      <td>6_witness_spirit_tongue_mouth</td>\n",
       "      <td>[witness, spirit, tongue, mouth, hear, trumpet...</td>\n",
       "      <td>[if i bear witness of myself my witness is not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>228</td>\n",
       "      <td>7_cubits_thereof_breadth_length</td>\n",
       "      <td>[cubits, thereof, breadth, length, pillars, ro...</td>\n",
       "      <td>[and the breadth of the entrance was ten cubit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>224</td>\n",
       "      <td>8_lion_wings_cherub_cherubim</td>\n",
       "      <td>[lion, wings, cherub, cherubim, wheels, young,...</td>\n",
       "      <td>[and the cherubim shall spread out their wings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>173</td>\n",
       "      <td>9_begat_obed_amariah_boaz</td>\n",
       "      <td>[begat, obed, amariah, boaz, nahshon, salmon, ...</td>\n",
       "      <td>[and obed begat jesse and jesse begat david, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>121</td>\n",
       "      <td>10_waters_sea_boat_wind</td>\n",
       "      <td>[waters, sea, boat, wind, rock, earth, ship, d...</td>\n",
       "      <td>[and thou didst divide the sea before them so ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>112</td>\n",
       "      <td>11_hath_gate_wall_rulers</td>\n",
       "      <td>[hath, gate, wall, rulers, brought, court, out...</td>\n",
       "      <td>[and i said unto the nobles and to the rulers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>12_mealoffering_oil_ephah_flour</td>\n",
       "      <td>[mealoffering, oil, ephah, flour, tenth, fine,...</td>\n",
       "      <td>[then shall he offer with the bullock a mealof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>42</td>\n",
       "      <td>13_shekels_shekel_sanctuary_silver</td>\n",
       "      <td>[shekels, shekel, sanctuary, silver, spoon, bo...</td>\n",
       "      <td>[his oblation was one silver platter the weigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>14_helambs_year_old_rams</td>\n",
       "      <td>[helambs, year, old, rams, helamb, hegoats, bu...</td>\n",
       "      <td>[and for the sacrifice of peaceofferings two o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>15_jubilee_generation_year_shall</td>\n",
       "      <td>[jubilee, generation, year, shall, reckon, est...</td>\n",
       "      <td>[but if he sanctify his field after the jubile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>16_hair_head_shave_beard</td>\n",
       "      <td>[hair, head, shave, beard, bald, grow, cutting...</td>\n",
       "      <td>[in that day will the lord shave with a razor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>17_macedonia_achaia_certain_brethren</td>\n",
       "      <td>[macedonia, achaia, certain, brethren, want, y...</td>\n",
       "      <td>[so that ye became an ensample to all that bel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>18_goats_male_sinoffering_prepare</td>\n",
       "      <td>[goats, male, sinoffering, prepare, pillow, te...</td>\n",
       "      <td>[one male of the goats for a sinoffering, one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>19_members_body_christ_severally</td>\n",
       "      <td>[members, body, christ, severally, member, hat...</td>\n",
       "      <td>[for even as we have many members in one body ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>20_chief_chiefs_esau_esaus</td>\n",
       "      <td>[chief, chiefs, esau, esaus, edom, horites, re...</td>\n",
       "      <td>[these are the chiefs of the sons of esau the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>21_answered_elihu_shuhite_bildad</td>\n",
       "      <td>[answered, elihu, shuhite, bildad, temanite, e...</td>\n",
       "      <td>[then answered bildad the shuhite and said, mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>22_faithful_acceptation_unrighteous_saying</td>\n",
       "      <td>[faithful, acceptation, unrighteous, saying, w...</td>\n",
       "      <td>[faithful is the saying for if we died with hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                        Name  \\\n",
       "0      -1  15735                      -1_unto_shall_thou_thy   \n",
       "1       0   8241                   0_jehovah_unto_said_shall   \n",
       "2       1   3545                         1_shall_thy_thou_ye   \n",
       "3       2    923                    2_son_sons_years_reigned   \n",
       "4       3    661                   3_wife_woman_said_husband   \n",
       "5       4    294                 4_gold_silver_thereof_rings   \n",
       "6       5    282         5_border_suburbs_journeyed_encamped   \n",
       "7       6    280               6_witness_spirit_tongue_mouth   \n",
       "8       7    228             7_cubits_thereof_breadth_length   \n",
       "9       8    224                8_lion_wings_cherub_cherubim   \n",
       "10      9    173                   9_begat_obed_amariah_boaz   \n",
       "11     10    121                     10_waters_sea_boat_wind   \n",
       "12     11    112                    11_hath_gate_wall_rulers   \n",
       "13     12     63             12_mealoffering_oil_ephah_flour   \n",
       "14     13     42          13_shekels_shekel_sanctuary_silver   \n",
       "15     14     34                    14_helambs_year_old_rams   \n",
       "16     15     30            15_jubilee_generation_year_shall   \n",
       "17     16     17                    16_hair_head_shave_beard   \n",
       "18     17     15        17_macedonia_achaia_certain_brethren   \n",
       "19     18     14           18_goats_male_sinoffering_prepare   \n",
       "20     19     14            19_members_body_christ_severally   \n",
       "21     20     13                  20_chief_chiefs_esau_esaus   \n",
       "22     21     13            21_answered_elihu_shuhite_bildad   \n",
       "23     22     12  22_faithful_acceptation_unrighteous_saying   \n",
       "\n",
       "                                       Representation  \\\n",
       "0   [unto, shall, thou, thy, god, jehovah, thee, y...   \n",
       "1   [jehovah, unto, said, shall, king, came, israe...   \n",
       "2   [shall, thy, thou, ye, god, thee, unto, hath, ...   \n",
       "3   [son, sons, years, reigned, children, thousand...   \n",
       "4   [wife, woman, said, husband, unto, nakedness, ...   \n",
       "5   [gold, silver, thereof, rings, fine, work, pur...   \n",
       "6   [border, suburbs, journeyed, encamped, lebanon...   \n",
       "7   [witness, spirit, tongue, mouth, hear, trumpet...   \n",
       "8   [cubits, thereof, breadth, length, pillars, ro...   \n",
       "9   [lion, wings, cherub, cherubim, wheels, young,...   \n",
       "10  [begat, obed, amariah, boaz, nahshon, salmon, ...   \n",
       "11  [waters, sea, boat, wind, rock, earth, ship, d...   \n",
       "12  [hath, gate, wall, rulers, brought, court, out...   \n",
       "13  [mealoffering, oil, ephah, flour, tenth, fine,...   \n",
       "14  [shekels, shekel, sanctuary, silver, spoon, bo...   \n",
       "15  [helambs, year, old, rams, helamb, hegoats, bu...   \n",
       "16  [jubilee, generation, year, shall, reckon, est...   \n",
       "17  [hair, head, shave, beard, bald, grow, cutting...   \n",
       "18  [macedonia, achaia, certain, brethren, want, y...   \n",
       "19  [goats, male, sinoffering, prepare, pillow, te...   \n",
       "20  [members, body, christ, severally, member, hat...   \n",
       "21  [chief, chiefs, esau, esaus, edom, horites, re...   \n",
       "22  [answered, elihu, shuhite, bildad, temanite, e...   \n",
       "23  [faithful, acceptation, unrighteous, saying, w...   \n",
       "\n",
       "                                  Representative_Docs  \n",
       "0   [and they that are far off shall come and buil...  \n",
       "1   [and jeremiah said the word of jehovah came un...  \n",
       "2   [let thy hand be upon the man of thy right han...  \n",
       "3   [zedekiah was twenty and one years old when he...  \n",
       "4   [and he came near unto her and the woman said ...  \n",
       "5   [and they shall make the ephod of gold of blue...  \n",
       "6   [and the border from the sea shall be hazareno...  \n",
       "7   [if i bear witness of myself my witness is not...  \n",
       "8   [and the breadth of the entrance was ten cubit...  \n",
       "9   [and the cherubim shall spread out their wings...  \n",
       "10  [and obed begat jesse and jesse begat david, a...  \n",
       "11  [and thou didst divide the sea before them so ...  \n",
       "12  [and i said unto the nobles and to the rulers ...  \n",
       "13  [then shall he offer with the bullock a mealof...  \n",
       "14  [his oblation was one silver platter the weigh...  \n",
       "15  [and for the sacrifice of peaceofferings two o...  \n",
       "16  [but if he sanctify his field after the jubile...  \n",
       "17  [in that day will the lord shave with a razor ...  \n",
       "18  [so that ye became an ensample to all that bel...  \n",
       "19  [one male of the goats for a sinoffering, one ...  \n",
       "20  [for even as we have many members in one body ...  \n",
       "21  [these are the chiefs of the sons of esau the ...  \n",
       "22  [then answered bildad the shuhite and said, mo...  \n",
       "23  [faithful is the saying for if we died with hi...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_info = topic_model.get_topic_info()\n",
    "topic_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de3066c",
   "metadata": {},
   "source": [
    "loop thru all topics and print top words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d4cd13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Topic -1 ---\n",
      "[('unto', 0.025876982226851995), ('shall', 0.02564436404690842), ('thou', 0.023693664085367234), ('thy', 0.023138002999135557), ('god', 0.020126246283719763), ('jehovah', 0.020110431402688866), ('thee', 0.020098989020936625), ('ye', 0.01908654359204315), ('said', 0.017330389926954532), ('man', 0.01534511546216039)]\n",
      "\n",
      "--- Topic 0 ---\n",
      "[('jehovah', 0.04001698576110717), ('unto', 0.02993815499587687), ('said', 0.024846192814911915), ('shall', 0.0231589750105912), ('king', 0.021137626173362904), ('came', 0.019620781512324225), ('israel', 0.018518370580220336), ('thou', 0.01705097227151194), ('god', 0.01680133231770259), ('ye', 0.01675737562127365)]\n",
      "\n",
      "--- Topic 1 ---\n",
      "[('shall', 0.03580392066493696), ('thy', 0.026231090131520696), ('thou', 0.02592020139503894), ('ye', 0.025728650563944216), ('god', 0.022421492780007213), ('thee', 0.020259513758410674), ('unto', 0.019830804030762768), ('hath', 0.019610557826691518), ('man', 0.018542463308133535), ('light', 0.014634323012072945)]\n",
      "\n",
      "--- Topic 2 ---\n",
      "[('son', 0.12805561387634118), ('sons', 0.09642621561495422), ('years', 0.06808498840679975), ('reigned', 0.06607259083659665), ('children', 0.06238211185246405), ('thousand', 0.056955458607535495), ('families', 0.03965268089849169), ('reign', 0.037931855061771956), ('tribe', 0.03740261800023836), ('began', 0.03602257848864514)]\n",
      "\n",
      "--- Topic 3 ---\n",
      "[('wife', 0.04445142415495477), ('woman', 0.044251029747384686), ('said', 0.04319732653473899), ('husband', 0.037700416613023535), ('unto', 0.03374580590364443), ('nakedness', 0.02994925715253773), ('hath', 0.024027251024753955), ('mary', 0.023152691027723424), ('thou', 0.02244508100331373), ('shall', 0.021869269798501862)]\n",
      "\n",
      "--- Topic 4 ---\n",
      "[('gold', 0.1642451761124698), ('silver', 0.07683363078516536), ('thereof', 0.07033274091213383), ('rings', 0.06460548103291676), ('fine', 0.05543923463536285), ('work', 0.05156805270682665), ('pure', 0.05009783020386135), ('iron', 0.048330301301006795), ('blue', 0.04764802699790019), ('make', 0.04674375208891827)]\n",
      "\n",
      "--- Topic 5 ---\n",
      "[('border', 0.14918357760455317), ('suburbs', 0.1434320479562219), ('journeyed', 0.08685112443867997), ('encamped', 0.08397659810831275), ('lebanon', 0.07175238529264921), ('sea', 0.055984497685371934), ('cities', 0.05507521100841443), ('east', 0.04307737260253639), ('west', 0.04243141045304994), ('went', 0.04077017128840446)]\n",
      "\n",
      "--- Topic 6 ---\n",
      "[('witness', 0.11025833235589692), ('spirit', 0.0896527454564788), ('tongue', 0.07833355404504917), ('mouth', 0.06252018508806619), ('hear', 0.05368957733592055), ('trumpet', 0.04836674769305826), ('lips', 0.04449808534074139), ('harp', 0.044118919440103856), ('sing', 0.037840201622778215), ('false', 0.03631199145963152)]\n",
      "\n",
      "--- Topic 7 ---\n",
      "[('cubits', 0.3129580452322458), ('thereof', 0.13494601605121448), ('breadth', 0.13208291512072928), ('length', 0.11057961334500714), ('pillars', 0.09709857182276897), ('round', 0.08148372998331306), ('gate', 0.07639277107596225), ('measured', 0.07367452891481832), ('cubit', 0.07232792453453554), ('court', 0.06462306924785192)]\n",
      "\n",
      "--- Topic 8 ---\n",
      "[('lion', 0.11265493814921407), ('wings', 0.09018711036499208), ('cherub', 0.06854305667542701), ('cherubim', 0.06743263483791224), ('wheels', 0.05965560325950086), ('young', 0.05224569703318456), ('living', 0.05101261914959002), ('kind', 0.05030656748009967), ('lions', 0.04993956466840386), ('faces', 0.04210251756829299)]\n",
      "\n",
      "--- Topic 9 ---\n",
      "[('begat', 0.4563450374429452), ('obed', 0.0904713623105784), ('amariah', 0.06144672936000048), ('boaz', 0.0567032735840917), ('nahshon', 0.05428281738634703), ('salmon', 0.05142852235112187), ('azariah', 0.05130660442757035), ('elishama', 0.04349783132156719), ('hazarshual', 0.04230012844616805), ('shallum', 0.040502338274351214)]\n",
      "\n",
      "--- Topic 10 ---\n",
      "[('waters', 0.16050488774672242), ('sea', 0.12131020839917406), ('boat', 0.1199586933761199), ('wind', 0.05782446904542371), ('rock', 0.054436603172369175), ('earth', 0.0498695532061802), ('ship', 0.04814658286365617), ('dry', 0.04015787248311753), ('sailed', 0.04008817261003215), ('depths', 0.03790967640685949)]\n",
      "\n",
      "--- Topic 11 ---\n",
      "[('hath', 0.08203898406560602), ('gate', 0.05110488985687749), ('wall', 0.04747927756347123), ('rulers', 0.04514352610944061), ('brought', 0.04355769739198052), ('court', 0.040529295053171197), ('outer', 0.03466188244750136), ('behold', 0.0315536528506666), ('feet', 0.030310569210958052), ('set', 0.028655727248837342)]\n",
      "\n",
      "--- Topic 12 ---\n",
      "[('mealoffering', 0.30828113453288386), ('oil', 0.24476745165245525), ('ephah', 0.23028848954213338), ('flour', 0.22715273477736458), ('tenth', 0.19898578607331946), ('fine', 0.1920730211650726), ('mingled', 0.17253784401323158), ('hin', 0.13614555761575683), ('parts', 0.12648291071337386), ('drinkofferings', 0.09618871628466963)]\n",
      "\n",
      "--- Topic 13 ---\n",
      "[('shekels', 0.5805618725592951), ('shekel', 0.3814277127399228), ('sanctuary', 0.24356018927294035), ('silver', 0.2433885846987343), ('spoon', 0.1809054575215321), ('bowl', 0.17348501560847102), ('platter', 0.16913547935368078), ('seventy', 0.1500206948367007), ('golden', 0.14671591128512376), ('flour', 0.14241668565859583)]\n",
      "\n",
      "--- Topic 14 ---\n",
      "[('helambs', 0.39181986117176715), ('year', 0.3599275270406676), ('old', 0.34561017350262846), ('rams', 0.32105412056955335), ('helamb', 0.24842094776983928), ('hegoats', 0.245057923442541), ('bullock', 0.21438219300275857), ('ram', 0.21394659791793053), ('oxen', 0.21224744027602668), ('peaceofferings', 0.20381470081179465)]\n",
      "\n",
      "--- Topic 15 ---\n",
      "[('jubilee', 0.34698573057132265), ('generation', 0.17630868433762484), ('year', 0.16220769486439585), ('shall', 0.11561969710326866), ('reckon', 0.08279337725988835), ('estimation', 0.07602986203321367), ('unto', 0.07347434202446525), ('years', 0.06825334891225672), ('bought', 0.06756777765560787), ('according', 0.059549746253189116)]\n",
      "\n",
      "--- Topic 16 ---\n",
      "[('hair', 0.43560424317618135), ('head', 0.321954461525988), ('shave', 0.2939713684724896), ('beard', 0.161140912709389), ('bald', 0.12323760634468267), ('grow', 0.11025259347873233), ('cuttings', 0.10048761768353151), ('shall', 0.09939754572398352), ('long', 0.09865955855219506), ('locks', 0.09223843481467114)]\n",
      "\n",
      "--- Topic 17 ---\n",
      "[('macedonia', 0.6846999620706488), ('achaia', 0.1855766817349979), ('certain', 0.08480621829336607), ('brethren', 0.08318172421063325), ('want', 0.07675030500277963), ('ye', 0.06711762833012025), ('gospel', 0.06413850365884004), ('hath', 0.06229784786047005), ('wereafflicted', 0.06115018120824731), ('unprepared', 0.06115018120824731)]\n",
      "\n",
      "--- Topic 18 ---\n",
      "[('goats', 1.1917052452423522), ('male', 1.056321784346166), ('sinoffering', 1.0110326865614947), ('prepare', 0.1731728788939166), ('pillow', 0.1450221810379398), ('teraphim', 0.11200631101569443), ('goat', 0.1023845993754911), ('hair', 0.08569263800187175), ('blemish', 0.08569263800187175), ('messengers', 0.08505319528561975)]\n",
      "\n",
      "--- Topic 19 ---\n",
      "[('members', 1.039302204242472), ('body', 0.7278852205416186), ('christ', 0.26272444591379), ('severally', 0.208691530172184), ('member', 0.20389548748506253), ('hath', 0.12787452981885958), ('belial', 0.12551879300640237), ('concord', 0.12551879300640237), ('schism', 0.12551879300640237), ('believer', 0.11639938214887272)]\n",
      "\n",
      "--- Topic 20 ---\n",
      "[('chief', 0.7294552151045868), ('chiefs', 0.47902725306415256), ('esau', 0.26501083834860706), ('esaus', 0.23056577919410953), ('edom', 0.2293724813481191), ('horites', 0.15192212793004659), ('reuel', 0.14004416307216158), ('sons', 0.13403171648233989), ('eliphaz', 0.13396833278347764), ('wife', 0.11751351187339273)]\n",
      "\n",
      "--- Topic 21 ---\n",
      "[('answered', 0.6296409438381594), ('elihu', 0.5951876930566866), ('shuhite', 0.39651390732714964), ('bildad', 0.39651390732714964), ('temanite', 0.3874014262216188), ('eliphaz', 0.341619248597868), ('said', 0.3035593946486658), ('naamathite', 0.27177832526662976), ('zophar', 0.27177832526662976), ('barachel', 0.1474392173885721)]\n",
      "\n",
      "--- Topic 22 ---\n",
      "[('faithful', 0.7007073677417484), ('acceptation', 0.2010534782571438), ('unrighteous', 0.14658854072832908), ('saying', 0.13491002171037073), ('worthy', 0.12036104184901414), ('profuse', 0.10840259396007479), ('good', 0.10214355528877192), ('kisses', 0.1005267391285719), ('affirm', 0.09591999869791645), ('confidently', 0.09265170179544197)]\n"
     ]
    }
   ],
   "source": [
    "for topic_id in topic_model.get_topic_info()[\"Topic\"]:\n",
    "    print(f\"\\n--- Topic {topic_id} ---\")\n",
    "    print(topic_model.get_topic(topic_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73a92705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.8243261450586175,
          0.8243261450586175,
          0
         ],
         "xaxis": "x",
         "y": [
          -5,
          -5,
          -15,
          -15
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.8243261450586175,
          0.9529522131472292,
          0.9529522131472292,
          0
         ],
         "xaxis": "x",
         "y": [
          -10,
          -10,
          -25,
          -25
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,65,54)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.9748211389593866,
          0.9748211389593866,
          0
         ],
         "xaxis": "x",
         "y": [
          -55,
          -55,
          -65,
          -65
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,65,54)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.9876911541726736,
          0.9876911541726736,
          0.9748211389593866
         ],
         "xaxis": "x",
         "y": [
          -45,
          -45,
          -60,
          -60
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          1.0066456686931327,
          1.0066456686931327,
          0.9876911541726736
         ],
         "xaxis": "x",
         "y": [
          -35,
          -35,
          -52.5,
          -52.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(35,205,205)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.957778911974946,
          0.957778911974946,
          0
         ],
         "xaxis": "x",
         "y": [
          -75,
          -75,
          -85,
          -85
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          1.0066456686931327,
          1.028356176318393,
          1.028356176318393,
          0.957778911974946
         ],
         "xaxis": "x",
         "y": [
          -43.75,
          -43.75,
          -80,
          -80
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.9529522131472292,
          1.1043878918407344,
          1.1043878918407344,
          1.028356176318393
         ],
         "xaxis": "x",
         "y": [
          -17.5,
          -17.5,
          -61.875,
          -61.875
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(133,20,75)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.888629617757088,
          0.888629617757088,
          0
         ],
         "xaxis": "x",
         "y": [
          -95,
          -95,
          -105,
          -105
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,220,0)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.7761151198830245,
          0.7761151198830245,
          0
         ],
         "xaxis": "x",
         "y": [
          -115,
          -115,
          -125,
          -125
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.888629617757088,
          1.0205550400730354,
          1.0205550400730354,
          0.7761151198830245
         ],
         "xaxis": "x",
         "y": [
          -100,
          -100,
          -120,
          -120
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          1.1043878918407344,
          1.1274281597351807,
          1.1274281597351807,
          1.0205550400730354
         ],
         "xaxis": "x",
         "y": [
          -39.6875,
          -39.6875,
          -110,
          -110
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(40,35,35)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.8496037602740848,
          0.8496037602740848,
          0
         ],
         "xaxis": "x",
         "y": [
          -145,
          -145,
          -155,
          -155
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(40,35,35)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.8986864721491915,
          0.8986864721491915,
          0.8496037602740848
         ],
         "xaxis": "x",
         "y": [
          -135,
          -135,
          -150,
          -150
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.8084169813304392,
          0.8084169813304392,
          0
         ],
         "xaxis": "x",
         "y": [
          -165,
          -165,
          -175,
          -175
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.8986864721491915,
          1.0039474954657854,
          1.0039474954657854,
          0.8084169813304392
         ],
         "xaxis": "x",
         "y": [
          -142.5,
          -142.5,
          -170,
          -170
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,65,54)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.31386203436925175,
          0.31386203436925175,
          0
         ],
         "xaxis": "x",
         "y": [
          -195,
          -195,
          -205,
          -205
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,65,54)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.31386203436925175,
          0.46410885040238004,
          0.46410885040238004,
          0
         ],
         "xaxis": "x",
         "y": [
          -200,
          -200,
          -215,
          -215
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,65,54)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.7538337651325275,
          0.7538337651325275,
          0.46410885040238004
         ],
         "xaxis": "x",
         "y": [
          -185,
          -185,
          -207.5,
          -207.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,65,54)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.7538337651325275,
          0.8314994508126677,
          0.8314994508126677,
          0
         ],
         "xaxis": "x",
         "y": [
          -196.25,
          -196.25,
          -225,
          -225
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          1.0039474954657854,
          1.1420936499909753,
          1.1420936499909753,
          0.8314994508126677
         ],
         "xaxis": "x",
         "y": [
          -156.25,
          -156.25,
          -210.625,
          -210.625
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          1.1274281597351807,
          1.4005895350637534,
          1.4005895350637534,
          1.1420936499909753
         ],
         "xaxis": "x",
         "y": [
          -74.84375,
          -74.84375,
          -183.4375,
          -183.4375
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "autosize": false,
        "height": 545,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "hovermode": "closest",
        "plot_bgcolor": "#ECEFF1",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Hierarchical Clustering</b>",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "mirror": "allticks",
         "rangemode": "tozero",
         "showgrid": false,
         "showline": true,
         "showticklabels": true,
         "ticks": "outside",
         "type": "linear",
         "zeroline": false
        },
        "yaxis": {
         "mirror": "allticks",
         "range": [
          -230,
          0
         ],
         "rangemode": "tozero",
         "showgrid": false,
         "showline": true,
         "showticklabels": true,
         "tickmode": "array",
         "ticks": "outside",
         "ticktext": [
          "9_begat_obed_amariah",
          "2_son_sons_years",
          "20_chief_chiefs_esau",
          "21_answered_elihu_shuhite",
          "17_macedonia_achaia_certain",
          "19_members_body_christ",
          "22_faithful_acceptation_unr...",
          "16_hair_head_shave",
          "18_goats_male_sinoffering",
          "15_jubilee_generation_year",
          "14_helambs_year_old",
          "12_mealoffering_oil_ephah",
          "13_shekels_shekel_sanctuary",
          "5_border_suburbs_journeyed",
          "10_waters_sea_boat",
          "8_lion_wings_cherub",
          "4_gold_silver_thereof",
          "7_cubits_thereof_breadth",
          "11_hath_gate_wall",
          "1_shall_thy_thou",
          "0_jehovah_unto_said",
          "3_wife_woman_said",
          "6_witness_spirit_tongue"
         ],
         "tickvals": [
          -5,
          -15,
          -25,
          -35,
          -45,
          -55,
          -65,
          -75,
          -85,
          -95,
          -105,
          -115,
          -125,
          -135,
          -145,
          -155,
          -165,
          -175,
          -185,
          -195,
          -205,
          -215,
          -225
         ],
         "type": "linear",
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_hierarchy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c1d99",
   "metadata": {},
   "source": [
    "Stage 1 — Embedding and Clustering\n",
    "\n",
    "Do not remove stopwords\n",
    "\n",
    "BERTopic creates topics in two phases.\n",
    "The first phase uses sentence embeddings to cluster documents.\n",
    "During this step, removing stopwords is harmful because:\n",
    "\n",
    "Removing stopwords destroys sentence meaning\n",
    "\n",
    "Embeddings expect natural, full sentences\n",
    "\n",
    "Context is lost if you remove words like “and”, “of”, “to”, etc.\n",
    "\n",
    "BERTopic performs worse when the input text is heavily cleaned\n",
    "\n",
    "So the text going into the embedding step should be nearly raw, except for light cleaning like lowercasing and trimming whitespace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d278f2",
   "metadata": {},
   "source": [
    "Stage 2 — Topic Representation (c-TF-IDF)\n",
    "\n",
    "Stopwords can be removed here\n",
    "\n",
    "After the clusters are created, BERTopic uses c-TF-IDF to extract the top representative words for each topic.\n",
    "This step benefits from removing stopwords because it makes the topic words more meaningful and less generic.\n",
    "\n",
    "However, you do not remove stopwords manually.\n",
    "BERTopic allows you to specify stopwords directly so it handles them only during the representation step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02940f3",
   "metadata": {},
   "source": [
    "**FIX IMPORT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d886826f",
   "metadata": {},
   "source": [
    "Check topic 0 to ensure stop words removed now. \n",
    "\n",
    "\n",
    "Upon checking for the first time even though I expected to see no stop words I got those old ways of writing pronouns which are in itself not meaningful at all\n",
    "\n",
    "\n",
    "[('thou', 0.014937373550020365),\n",
    " ('hast', 0.014405130728016153),\n",
    " ('thee', 0.0130547974710153),\n",
    " ('precepts', 0.012812065086448337),\n",
    " ('thy', 0.012758845182956701),\n",
    " ('art', 0.01129255999103892),\n",
    " ('didst', 0.010644017168714534),\n",
    " ('thyself', 0.010014345661687142),\n",
    " ('shalt', 0.008669805195656523),\n",
    " ('thine', 0.008116947841383953)]\n",
    "\n",
    "\n",
    " So i decided to modify the stop words list to fit my dataset better. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2183e51",
   "metadata": {},
   "source": [
    "(3) **TOPIC ANALYSIS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565cfab6",
   "metadata": {},
   "source": [
    "topic_model.get_topics() returns BERTopic’s internal dictionary of topics: each key is a topic ID (e.g., -1, 0, 1, …) and each value is a list of tuples capturing the top n words for that topic and their c-TF-IDF scores. So when you iterate or inspect that dictionary, you’re looking at the set of learned topics, including the special “outlier” topic -1.\n",
    "\n",
    "\n",
    "-1 -> for docs that didnt fit well into any learned topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ae7595",
   "metadata": {},
   "source": [
    "**CONCLUSION**\n",
    "\n",
    "\n",
    "So after getting my topics with Bertopic I got about 394 of them. For a person who doesn't understand the Bible it seems too big, so I decided to take extra steps and nail down more 'meningful' topics and help me to interpret them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3a9c64",
   "metadata": {},
   "source": [
    "(3) **BIBLE TOPIC INTERPRETATION**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
